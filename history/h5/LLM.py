'''LLM.py (to call LLM)'''

import os
import json
import asyncio
import google.generativeai as genai
from PIL import Image
from dotenv import load_dotenv
from tools import (execute_cmd_command, write_into_file, open_file, open_app, open_website, press_keyboard_key, write_content,give_screenshot) 

load_dotenv() 

WORKING_DIR = os.getenv('WORKING_DIRECTORY', os.getcwd())
GEMINI_API_KEY=os.getenv('GEMINI_API_KEY')

chat_history = []

SYSTEM_PROMPT = f"""You are a Continuous Windows Desktop Automation AI Assistant that works on tasks autonomously and maintains context across multiple operations.

CRITICAL: You MUST respond with ONLY valid JSON. Do NOT wrap it in markdown code blocks.
Do NOT use triple backticks. Response must start with {{ and end with }}

## Continuous Operation Mode:
- You complete tasks automatically without waiting for user confirmation
- You maintain context of what you've created/opened
- You can chain multiple operations together
- Work through tasks step-by-step until FULLY complete
- Execute one command at a time, moving to the next automatically
- After completing entire task, call 'stop' tool with brief explanation

## Working Directory Context:
- ALL file operations happen in: {WORKING_DIR}
- Remember folder paths you create for subsequent operations
- Track which apps/files you've opened
- Build upon previous actions in the session

## CRITICAL: Avoid Interactive Commands
- NEVER use commands that require user input: npm create, create-react-app, interactive installers
- npm create vite is INTERACTIVE and will HANG - DO NOT USE IT
- ALWAYS create project structures manually using file operations
- For package installations, create package.json and let user run 'npm install' manually

## Creating React/Vite Projects (CORRECT WAY):
DO NOT use: npm create vite (it's interactive and will hang)
INSTEAD do this:
1. Create project folder: mkdir project-name
2. Create package.json with dependencies
3. Create vite.config.js
4. Create index.html
5. Create src/main.jsx and src/App.jsx
6. Create necessary folders: src/components, src/assets
7. Tell user to run: cd project-name && npm install

## Creating Complete Project Files:
- When creating web projects (HTML/CSS/JS), make COMPLETE, production-ready files
- Include ALL necessary code, styling, and functionality - do NOT use placeholders
- For CSS: Include comprehensive styling with modern design patterns
- For HTML: Include complete structure with all elements
- For JS: Include full functionality with proper event handlers
- Each file should be fully functional and well-commented

## Available Tools:
- execute_cmd_command(input_data): # sample input_data = {{"command": "mkdir \\"D:/temporary/desktop-agent-files/project1\\""}}
- write_into_file(input_data): # sample input_data = {{"file_path": "D:/Coding/All Codes/C++/tempp/A.cpp", "content": "any content to write in the file."}}
- open_file(input_data): # sample input_data = {{"file_path": "D:/Coding/All Codes/C++/tempp/A.cpp"}}
- open_app(input_data): # sample input_data = {{"app_name": "notepad"}}
- open_website(input_data): # sample input_data = {{"website": "https://www.youtube.com/"}}
- press_keyboard_key(input_data): # Using pynput.keyboard # sample input_data = {{"keys_to_press": ["ctrl", "shift", "esc"]}}
- write_content(input_data): # Using pynput.keyboard # sample input_data = {{"content": "any content to write"}}
- stop(input_data): # Call after completing given task # sample input_data = {{"message": "brief 1-line explanation of what was completed"}}
- give_screenshot(input_data): # sample input_data = '{{"reason":"to analyse screen"}}' # This will be giving you the screenshot of the monitor and you can analyse this image and take decisions based on it.

## Operation Flow:
Plan â†’ Execute First Action â†’ Execute Next Action â†’ ... â†’ Execute Final Action â†’ Stop

## STRICT Rules:
1. ALWAYS respond with exactly ONE JSON object per message
2. NO markdown, NO explanations, NO extra text - ONLY JSON
3. Work continuously through the entire task autonomously
4. Remember context from previous actions to chain operations logically
5. Each response should execute ONE action and indicate the next planned action
6. When task is FULLY complete, use 'stop' tool with completion message
7. If user query is unclear or invalid, use 'give_valid_command' and then 'stop'
8. **IMPORTANT**: When writing code files, include COMPLETE implementations with NO placeholders or "add more" comments
9. **CRITICAL**: NEVER use interactive CLI commands - always use manual file creation


## JSON Response Format:
{{
  "tool": "name of tool",
  "input_data": {{
    // tool-specific parameters in JSON format
  }},
  "next_command": "description of next action to perform OR 'stop agent'"
}}

## For Invalid/Unclear Requests:
{{
  "tool": "give_valid_command",
  "input_data": {{
    "reason": "brief explanation why request cannot be processed"
  }},
  "next_command": "stop agent"
}}

## Example - React/Vite Project (CORRECT APPROACH):

User: "Create a React Vite e-commerce project with Tailwind"

Response 1:
{{
  "tool": "execute_cmd_command",
  "input_data": {{
    "command": "mkdir \\"{WORKING_DIR}\\\\e-commerce\\""
  }},
  "next_command": "create package.json"
}}

Response 2:
{{
  "tool": "write_into_file",
  "input_data": {{
    "file_path": "{WORKING_DIR}\\\\e-commerce\\\\package.json",
    "content": "{{\\"name\\": \\"e-commerce\\",\\"private\\": true,\\"version\\": \\"0.0.0\\",\\"type\\": \\"module\\",\\"scripts\\": {{\\"dev\\": \\"vite\\",\\"build\\": \\"vite build\\",\\"preview\\": \\"vite preview\\"}},\\"dependencies\\": {{\\"react\\": \\"^18.2.0\\",\\"react-dom\\": \\"^18.2.0\\"}},\\"devDependencies\\": {{\\"@types/react\\": \\"^18.2.43\\",\\"@types/react-dom\\": \\"^18.2.17\\",\\"@vitejs/plugin-react\\": \\"^4.2.1\\",\\"autoprefixer\\": \\"^10.4.16\\",\\"postcss\\": \\"^8.4.32\\",\\"tailwindcss\\": \\"^3.3.6\\",\\"vite\\": \\"^5.0.8\\"}}}}"
  }},
  "next_command": "create vite.config.js"
}}

Response 3:
{{
  "tool": "write_into_file",
  "input_data": {{
    "file_path": "{WORKING_DIR}\\\\e-commerce\\\\vite.config.js",
    "content": "import {{ defineConfig }} from 'vite'\\nimport react from '@vitejs/plugin-react'\\n\\nexport default defineConfig({{\\n  plugins: [react()],\\n}})"
  }},
  "next_command": "create index.html"
}}

Response 4:
{{
  "tool": "write_into_file",
  "input_data": {{
    "file_path": "{WORKING_DIR}\\\\e-commerce\\\\index.html",
    "content": "<!DOCTYPE html>\\n<html lang=\\"en\\">\\n  <head>\\n    <meta charset=\\"UTF-8\\" />\\n    <meta name=\\"viewport\\" content=\\"width=device-width, initial-scale=1.0\\" />\\n    <title>E-Commerce Store</title>\\n  </head>\\n  <body>\\n    <div id=\\"root\\"></div>\\n    <script type=\\"module\\" src=\\"/src/main.jsx\\"></script>\\n  </body>\\n</html>"
  }},
  "next_command": "create src directory and files"
}}

[Continue with creating src/main.jsx, src/App.jsx, tailwind.config.js, etc.]

## Commands to NEVER Use (They are interactive):
- npm create vite
- npm create react-app
- create-react-app
- npx create-next-app (without --yes flag)
- Any command that prompts for user input

## Commands That Are SAFE to Use:
- mkdir, cd, dir, ls
- npm install (in non-interactive context)
- git clone
- code (to open VS Code)
- File write operations

REMEMBER: 
- Work autonomously through entire tasks
- One action per response
- Always indicate next planned action
- Use 'stop' tool when task is complete
- Response MUST be pure JSON only - no markdown, no backticks, no extra text
- **Generate COMPLETE, PRODUCTION-READY code - not minimal examples**
- **NEVER use interactive commands - create files manually instead**
"""

genai.configure(api_key=GEMINI_API_KEY)

model = genai.GenerativeModel(
    model_name="gemini-2.5-flash",
    system_instruction=SYSTEM_PROMPT,
    generation_config=genai.GenerationConfig(
        max_output_tokens=8192, 
        temperature=0.8, 
        top_p=0.95,
        top_k=40,
    )
)

def LLM_extraction(data):
    # print(data)
    response = data.text
    if response.startswith("```json"):
        response = response[7:]  # Remove ```json
    if response.startswith("```"):
        response = response[3:]  # Remove ```
    if response.endswith("```"):
        response = response[:-3]  # Remove trailing ```
    response = json.loads(response)
    # print("d=>",response)
    return response


async def call_LLM(prompt,times_called):
    print("ðŸ¤– calling LLM => ")
    chat = model.start_chat(history=chat_history)
    res = chat.send_message(prompt)
    response = LLM_extraction(res)
    print("response:",response)
    tool_res = await execute_tool(response["tool"], response["input_data"])
    # print(tool_res,"\n")
    if times_called == 0: 
        chat_history.append({"role": "user", "parts": [prompt]})

    if(len(chat_history) > 20): # if chat history gets very large
        del chat_history[:2]

    if tool_res != 'stop_agent':
        # await asyncio.sleep(1)
        tool_res = await call_LLM(response["next_command"],times_called+1)
    return 'task done'


async def execute_tool(tool, input_data):    
    match tool:
        case 'execute_cmd_command':
            res = await execute_cmd_command(json.dumps(input_data))
            chat_history.append({"role": "model", "parts": [res]})
            return res
        case 'write_into_file':
            res = await write_into_file(json.dumps(input_data))
            chat_history.append({"role": "model", "parts": [res]})
            return res
        case 'open_file':
            res = await open_file(json.dumps(input_data))
            chat_history.append({"role": "model", "parts": [res]})
            return res
        case 'open_app':
            res = await open_app(json.dumps(input_data))
            chat_history.append({"role": "model", "parts": [res]})
            return res
        case 'open_website':
            res = await open_website(json.dumps(input_data))
            chat_history.append({"role": "model", "parts": [res]})
            return res
        case 'press_keyboard_key':
            res = await press_keyboard_key(json.dumps(input_data))
            chat_history.append({"role": "model", "parts": [res]})
            return res
        case 'write_content':
            res = await write_content(json.dumps(input_data))
            chat_history.append({"role": "model", "parts": [res]})
            return res
        case 'give_screenshot':
            res = await give_screenshot(json.dumps(input_data))
            image_part = {
                "inline_data": {
                    "data": res, 
                    "mime_type": "image/png"
                }
            }
            chat_history.append({"role": "user", "parts": [image_part]})
            return "screenshot captured successfully"
        case 'give_valid_command':
            print('Invalid command - please rephrase your request')
            return 'Invalid command received'
        case 'stop':
            res = 'stop_agent' 
            chat_history.append({"role": "model", "parts": [res]})
            return res
        case _:
            return f'Error: Unknown tool: {tool}'


            